"""
Ingest all text/PDF files in ./data,
embed with intfloat/e5-small-v2,
and persist to ./chroma_db for later retrieval.

Run once:
  python ingest.py
"""

import os
from pathlib import Path
from dotenv import load_dotenv

from langchain_community.document_loaders import TextLoader, PyPDFLoader
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
BASE_DIR   = Path(__file__).parent
DATA_DIR   = BASE_DIR / "data"
CHROMA_DIR = BASE_DIR / "chroma_db"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1ï¸âƒ£ Load â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
docs = []
if not DATA_DIR.exists():
    raise SystemExit(f"âš   No ./data folder found at {DATA_DIR}.")

for fp in DATA_DIR.rglob("*"):
    if fp.is_file():
        if fp.suffix.lower() in {".txt", ".md"}:
            docs.extend(TextLoader(str(fp)).load())
        elif fp.suffix.lower() == ".pdf":
            docs.extend(PyPDFLoader(str(fp)).load())

if not docs:
    raise SystemExit(f"âš   No text or PDF files found in {DATA_DIR} â€“ add contract/law files first.")

print(f"ğŸ“„  Loaded {len(docs)} raw documents.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2ï¸âƒ£ Split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
splits   = splitter.split_documents(docs)

print(f"âœ‚ï¸  Split into {len(splits)} chunks.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3ï¸âƒ£ Embed & store â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
emb = HuggingFaceEmbeddings(model_name="intfloat/e5-small-v2")

CHROMA_DIR.mkdir(exist_ok=True)

vectordb = Chroma.from_documents(
    documents=splits,
    embedding=emb,
    persist_directory=str(CHROMA_DIR)
)

print(f"âœ…  Ingest complete â€“ {len(splits):,} chunks saved to {CHROMA_DIR}/")
